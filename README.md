<div align="center">

# BM-TSE

_Brainprint-Modulated Target Speaker Extraction_

[![Paper](https://img.shields.io/badge/arXiv-Ready%20to%20Go-red)](https://arxiv.org/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-green.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org)

</div>

<div align="center">
<img src="figure/main.png" style="width: 95%;" />
</div>

## ðŸŽ¯ Overview

BM-TSE is a novel, end-to-end framework designed for personalized and high-fidelity neuro-steered Target Speaker Extraction (TSE).
It aims to resolve two core issues in existing models: the non-stationarity of EEG signals and high inter-subject variability.

The model achieves state-of-the-art performance on the public KUL and Cocktail Party datasets.
